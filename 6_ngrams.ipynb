{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n",
    "N-grams are overlapping sequences of $n$ words, i.e., sequences of two words at a time (bigrams), three words at a time (trigrams), or some other number, like 4-grams or 5-grams. \n",
    "\n",
    "## Make ngrams manually\n",
    "\n",
    "We can make a list of lists that is a bigram representation of a test sentence, like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testText='The quick brown fox jumped over the lazy dogs!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTokens=nltk.word_tokenize(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dogs', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigrams\n",
    "can get frequent bigrams and pharses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 原始方式实现ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams=[]\n",
    "for i, item in enumerate(testTokens):\n",
    "    if i<(len(testTokens)-1):\n",
    "        nextOne=testTokens[i+1]\n",
    "        bigrams.append([item,nextOne])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'quick'],\n",
       " ['quick', 'brown'],\n",
       " ['brown', 'fox'],\n",
       " ['fox', 'jumped'],\n",
       " ['jumped', 'over'],\n",
       " ['over', 'the'],\n",
       " ['the', 'lazy'],\n",
       " ['lazy', 'dogs'],\n",
       " ['dogs', '!']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'quick')\n",
      "('quick', 'brown')\n",
      "('brown', 'fox')\n",
      "('fox', 'jumped')\n",
      "('jumped', 'over')\n",
      "('over', 'the')\n",
      "('the', 'lazy')\n",
      "('lazy', 'dogs')\n",
      "('dogs', '!')\n"
     ]
    }
   ],
   "source": [
    "for item in zip(testTokens, testTokens[1:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用元组创建ngram  built-in `zip()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'quick', 'brown'),\n",
       " ('quick', 'brown', 'fox'),\n",
       " ('brown', 'fox', 'jumped'),\n",
       " ('fox', 'jumped', 'over'),\n",
       " ('jumped', 'over', 'the'),\n",
       " ('over', 'the', 'lazy'),\n",
       " ('the', 'lazy', 'dogs'),\n",
       " ('lazy', 'dogs', '!')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(testTokens, testTokens[1:],testTokens[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dogs', '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dogs', '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(tokens):\n",
    "    return list(zip(tokens,tokens[1:],tokens[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用nltk内置方法创建ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'quick', 'brown'),\n",
       " ('quick', 'brown', 'fox'),\n",
       " ('brown', 'fox', 'jumped'),\n",
       " ('fox', 'jumped', 'over'),\n",
       " ('jumped', 'over', 'the'),\n",
       " ('over', 'the', 'lazy'),\n",
       " ('the', 'lazy', 'dogs'),\n",
       " ('lazy', 'dogs', '!')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "list(nltk.ngrams(testTokens,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析the Moonstone中的ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "moonStone=open('moonstone.md').read()\n",
    "moonStoneParts=moonStone.split('\\n## ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredge=moonStoneParts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "betTokens=nltk.word_tokenize(betteredge.lower())\n",
    "betTokens=[word for word in betTokens if word.isalpha()]\n",
    "betTrigrams=list(nltk.ngrams(betTokens,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('in', 'the', 'house'), 46),\n",
       " (('my', 'lady', 's'), 43),\n",
       " (('i', 'don', 't'), 39),\n",
       " (('miss', 'rachel', 's'), 35),\n",
       " (('one', 'of', 'the'), 34),\n",
       " (('i', 'can', 't'), 33),\n",
       " (('the', 'colonel', 's'), 33),\n",
       " (('of', 'the', 'diamond'), 32),\n",
       " (('said', 'the', 'sergeant'), 29),\n",
       " (('says', 'the', 'sergeant'), 28),\n",
       " (('of', 'the', 'moonstone'), 26),\n",
       " (('out', 'of', 'the'), 25),\n",
       " (('the', 'rest', 'of'), 23),\n",
       " (('the', 'shivering', 'sand'), 23),\n",
       " (('that', 'he', 'had'), 22),\n",
       " (('as', 'well', 'as'), 19),\n",
       " (('at', 'the', 'bottom'), 19),\n",
       " (('the', 'loss', 'of'), 18),\n",
       " (('to', 'my', 'lady'), 18),\n",
       " (('there', 'was', 'a'), 18)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(betTrigrams).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据Narrator 分别判断常用词组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrator(narr): \n",
    "    \"\"\" Just a convenience function for getting a narrator from the text. \"\"\" \n",
    "    narrators = {\"Betteredge\": 2, \"Clack\": 4, \"Bruff\": 5, \"Blake\": 6, \"Jennings\": 7}\n",
    "    moonstoneParts = moonStone.split('\\n## ') \n",
    "    narrText = moonstoneParts[narrators[narr]]\n",
    "    # Just print a few characters so that we can verify it. \n",
    "    print(narrText[:60].replace('\\n', ' ')) \n",
    "    return narrText  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Period  THE LOSS OF THE DIAMOND (1848)  The events rel\n"
     ]
    }
   ],
   "source": [
    "bet = narrator(\"Betteredge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeQuoted(tokens): \n",
    "    \"\"\" A function to remove tokens that happen between quotation marks\n",
    "    (i.e. to remove dialogue from a text). \"\"\" \n",
    "    outsideQuotes = []\n",
    "    insideQuotes = []\n",
    "    isInside = False\n",
    "    for token in tokens: \n",
    "        if token == '“':\n",
    "            isInside = True\n",
    "            continue\n",
    "        if token == '”': \n",
    "            isInside = False\n",
    "            continue\n",
    "        if isInside: \n",
    "            insideQuotes.append(token)\n",
    "        else:\n",
    "            outsideQuotes.append(token)\n",
    "    return outsideQuotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonNgrams(text, n): \n",
    "    tokens = nltk.word_tokenize(text) # 分词\n",
    "    tokens = removeQuoted(tokens) # 去掉所有引号内部分(包括对话)\n",
    "    tokensClean = [token for token in tokens if token.isalpha()] # 去掉所有标点(非aplpha)\n",
    "    ngrams = nltk.ngrams(tokensClean, n) # 创建ngrams\n",
    "    return collections.Counter(ngrams).most_common(10) # 计数统计 返回最多的10个词组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Period  THE LOSS OF THE DIAMOND (1848)  The events rel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('like', 'a', 'woman', 'in', 'a', 'dream', 'I'), 3),\n",
       " (('I', 'went', 'into', 'the', 'service', 'of', 'the'), 2),\n",
       " (('went', 'into', 'the', 'service', 'of', 'the', 'old'), 2),\n",
       " (('into', 'the', 'service', 'of', 'the', 'old', 'lord'), 2),\n",
       " (('my', 'lady', 'took', 'an', 'interest', 'in', 'the'), 2),\n",
       " (('pipe', 'and', 'took', 'a', 'turn', 'at', 'ROBINSON'), 2),\n",
       " (('and', 'took', 'a', 'turn', 'at', 'ROBINSON', 'CRUSOE'), 2),\n",
       " (('took', 'a', 'turn', 'at', 'ROBINSON', 'CRUSOE', 'Before'), 2),\n",
       " (('a', 'turn', 'at', 'ROBINSON', 'CRUSOE', 'Before', 'I'), 2),\n",
       " (('turn', 'at', 'ROBINSON', 'CRUSOE', 'Before', 'I', 'had'), 2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonNgrams(narrator(\"Betteredge\"), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Narrative  Contributed by MISS CLACK; niece of the lat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('may', 'be', 'the', 'consequence', 'of', 'a', 'mission'), 3),\n",
       " (('the', 'fallen', 'nature', 'which', 'we', 'all', 'inherit'), 2),\n",
       " (('fallen', 'nature', 'which', 'we', 'all', 'inherit', 'from'), 2),\n",
       " (('once', 'embarked', 'on', 'a', 'career', 'of', 'manifest'), 2),\n",
       " (('embarked', 'on', 'a', 'career', 'of', 'manifest', 'usefulness'), 2),\n",
       " (('Miss', 'Jane', 'Ann', 'Stamper', 'on', 'my', 'lap'), 2),\n",
       " (('I', 'was', 'left', 'alone', 'in', 'the', 'room'), 2),\n",
       " (('First', 'Narrative', 'Contributed', 'by', 'MISS', 'CLACK', 'niece'), 1),\n",
       " (('Narrative', 'Contributed', 'by', 'MISS', 'CLACK', 'niece', 'of'), 1),\n",
       " (('Contributed', 'by', 'MISS', 'CLACK', 'niece', 'of', 'the'), 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonNgrams(narrator(\"Clack\"), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Narrative  Contributed by MISS CLACK; niece of the lat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('my', 'aunt', 's'), 14),\n",
       " (('Lady', 'Verinder', 's'), 14),\n",
       " (('out', 'of', 'the'), 13),\n",
       " (('which', 'I', 'had'), 12),\n",
       " (('in', 'Montagu', 'Square'), 10),\n",
       " (('in', 'the', 'room'), 9),\n",
       " (('on', 'the', 'subject'), 8),\n",
       " (('the', 'subject', 'of'), 8),\n",
       " (('of', 'the', 'house'), 8),\n",
       " (('one', 'of', 'the'), 8)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonNgrams(narrator(\"Clack\"), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third Narrative  Contributed by FRANKLIN BLAKE  ### Chapter \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('which', 'I', 'had'), 20),\n",
       " (('looked', 'at', 'me'), 16),\n",
       " (('that', 'I', 'had'), 16),\n",
       " (('he', 'said', 'I'), 14),\n",
       " (('one', 'of', 'the'), 12),\n",
       " (('to', 'me', 'I'), 12),\n",
       " (('that', 'he', 'was'), 11),\n",
       " (('that', 'I', 'was'), 10),\n",
       " (('I', 'might', 'have'), 10),\n",
       " (('said', 'Ezra', 'Jennings'), 10)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonNgrams(narrator(\"Blake\"), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
