{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    "WordNet, as the name implies, is a network of words, where words are connected by relations like `hyponym`, `hypernym`, `meronym`, and so on. You can use WordNet to generate wordlists (of, say, colors), or to categorize words. As usual, we'll start by importing the libraries we'll need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk\n",
    "import nltk\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogSyns=wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogSyns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog=dogSyns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hyponyms() # 不会很全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernyms()[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('placental.n.01')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernyms()[0].hypernyms()[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('mammal.n.01')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammal=dog.hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0]\n",
    "mammal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.max_depth(),dog.min_depth() # 树深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('vertebrate.n.01')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammal.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('mammal.n.01'),\n",
       " [Synset('vertebrate.n.01'),\n",
       "  [Synset('chordate.n.01'),\n",
       "   [Synset('animal.n.01'),\n",
       "    [Synset('organism.n.01'),\n",
       "     [Synset('living_thing.n.01'),\n",
       "      [Synset('whole.n.02'),\n",
       "       [Synset('object.n.01'),\n",
       "        [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getHypernyms(word):\n",
    "    print(word.max_depth())\n",
    "    return word.hypernyms()\n",
    "mammal.tree(getHypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('whole.n.02')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDepthHypernym(mammal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('whole.n.02')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDepthHypernym(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "house=wn.synsets('house')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('whole.n.02')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDepthHypernym(house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do with The Garden Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "garden=open('garden.md').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenTokens=nltk.word_tokenize(garden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenTags=nltk.pos_tag(garden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WordListCorpusReader' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-fdc0d709b71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 在tagging后除掉stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgardenNoStops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgardenTags\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'English'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-fdc0d709b71d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 在tagging后除掉stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgardenNoStops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgardenTags\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'English'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'WordListCorpusReader' object is not callable"
     ]
    }
   ],
   "source": [
    "# 在tagging后除掉stopwords\n",
    "gardenNoStops=[token for token in gardenTags if token[0] not in stopwords('English')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a mild viral infection involving the nose and respiratory passages (but not the lungs)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cold')[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cold')[3].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cold.n.01'), Synset('coldness.n.03'), Synset('cold.n.03')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cold',pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cold.a.01'),\n",
       " Synset('cold.a.02'),\n",
       " Synset('cold.s.03'),\n",
       " Synset('cold.s.04'),\n",
       " Synset('cold.s.05'),\n",
       " Synset('cold.s.06'),\n",
       " Synset('cold.s.07'),\n",
       " Synset('cold.s.08'),\n",
       " Synset('cold.s.09'),\n",
       " Synset('cold.s.10'),\n",
       " Synset('cold.s.11'),\n",
       " Synset('cold.s.12'),\n",
       " Synset('cold.s.13')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cold',pos='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有的lever 4 nouns\n",
    "categories=[]\n",
    "for tokenPos in gardenTags:\n",
    "    token = tokenPos[0] \n",
    "    pos = tokenPos[1] # the part of speech\n",
    "    if pos in ['NN','NNS']:\n",
    "        synset=wn.synsets(token,pos='n')\n",
    "        if type(synset) is list and len(synset)>0:\n",
    "            synset=synset[0]\n",
    "            categories.append(getDepthHypernym(synset)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Synset('matter.n.03'), 5948),\n",
       " (Synset('definite_quantity.n.01'), 3543),\n",
       " (Synset('substance.n.07'), 3431),\n",
       " (Synset('time_unit.n.01'), 882),\n",
       " (Synset('whole.n.02'), 241),\n",
       " (Synset('signal.n.01'), 27),\n",
       " (Synset('event.n.01'), 8)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(categories).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDepth6Hypernym(word):\n",
    "    if word.max_depth() >7:\n",
    "        return getDepth6Hypernym(word.hypernyms()[0])\n",
    "    return word.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有的lever 6 nouns\n",
    "categories=[]\n",
    "for tokenPos in gardenTags:\n",
    "    token = tokenPos[0] \n",
    "    pos = tokenPos[1] # the part of speech\n",
    "    if pos in ['NN','NNS']:\n",
    "        synset=wn.synsets(token,pos='n')\n",
    "        if type(synset) is list and len(synset)>0:\n",
    "            synset=synset[0]\n",
    "            categories.append(getDepth6Hypernym(synset)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Synset('chemical_element.n.01'), 3606),\n",
       " (Synset('inhibitor.n.01'), 2498),\n",
       " (Synset('chemical.n.01'), 1640),\n",
       " (Synset('radioactivity_unit.n.01'), 1243),\n",
       " (Synset('vitamin.n.01'), 933),\n",
       " (Synset('time_unit.n.01'), 882),\n",
       " (Synset('metric_capacity_unit.n.01'), 794),\n",
       " (Synset('metallic_element.n.01'), 702),\n",
       " (Synset('metric_weight_unit.n.01'), 375),\n",
       " (Synset('metric_linear_unit.n.01'), 373)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(categories).most_common(10)\n",
    "# he=>化学元素He 所以会出现chemical_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function lesk in module nltk.wsd:\n",
      "\n",
      "lesk(context_sentence, ambiguous_word, pos=None, synsets=None)\n",
      "    Return a synset for an ambiguous word in a context.\n",
      "    \n",
      "    :param iter context_sentence: The context sentence where the ambiguous word\n",
      "         occurs, passed as an iterable of words.\n",
      "    :param str ambiguous_word: The ambiguous word that requires WSD.\n",
      "    :param str pos: A specified Part-of-Speech (POS).\n",
      "    :param iter synsets: Possible synsets of the ambiguous word.\n",
      "    :return: ``lesk_sense`` The Synset() object with the highest signature overlaps.\n",
      "    \n",
      "    This function is an implementation of the original Lesk algorithm (1986) [1].\n",
      "    \n",
      "    Usage example::\n",
      "    \n",
      "        >>> lesk(['I', 'went', 'to', 'the', 'bank', 'to', 'deposit', 'money', '.'], 'bank', 'n')\n",
      "        Synset('savings_bank.n.02')\n",
      "    \n",
      "    [1] Lesk, Michael. \"Automatic sense disambiguation using machine\n",
      "    readable dictionaries: how to tell a pine cone from an ice cream\n",
      "    cone.\" Proceedings of the 5th Annual International Conference on\n",
      "    Systems Documentation. ACM, 1986.\n",
      "    http://dl.acm.org/citation.cfm?id=318728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lesk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
